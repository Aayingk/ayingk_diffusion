{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26b0ea2a",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: download in /root/miniconda3/envs/hjs/lib/python3.7/site-packages (0.3.5)\n",
      "Requirement already satisfied: six in /root/miniconda3/envs/hjs/lib/python3.7/site-packages (from download) (1.16.0)\n",
      "Requirement already satisfied: requests in /root/miniconda3/envs/hjs/lib/python3.7/site-packages (from download) (2.25.1)\n",
      "Requirement already satisfied: tqdm in /root/miniconda3/envs/hjs/lib/python3.7/site-packages (from download) (4.64.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /root/miniconda3/envs/hjs/lib/python3.7/site-packages (from requests->download) (1.26.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/miniconda3/envs/hjs/lib/python3.7/site-packages (from requests->download) (2022.5.18.1)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /root/miniconda3/envs/hjs/lib/python3.7/site-packages (from requests->download) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /root/miniconda3/envs/hjs/lib/python3.7/site-packages (from requests->download) (2.10)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !pip install https://ms-release.obs.cn-north-4.myhuaweicloud.com/1.9.0/MindSpore/gpu/x86_64/cuda-11.1/mindspore_gpu-1.9.0-cp37-cp37m-linux_x86_64.whl --trusted-host ms-release.obs.cn-north-4.myhuaweicloud.com -i https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "!pip install -q -U einops datasets matplotlib tqdm -i https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "!pip install download -i https://pypi.tuna.tsinghua.edu.cn/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3dbea0da",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 128, 128)\n",
      "dict_keys(['image'])\n",
      "<bound method Cell.parameters_and_names of Unet<\n",
      "  (init_conv): Conv2d<input_channels=1, output_channels=16, kernel_size=(7, 7), stride=(1, 1), pad_mode=pad, padding=3, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>\n",
      "  (time_mlp): SequentialCell<\n",
      "    (0): SinusoidalPositionEmbeddings<>\n",
      "    (1): Dense<input_channels=24, output_channels=96, has_bias=True>\n",
      "    (2): GELU<>\n",
      "    (3): Dense<input_channels=96, output_channels=96, has_bias=True>\n",
      "    >\n",
      "  (downs): CellList<\n",
      "    (0): CellList<\n",
      "      (0): ResnetBlock<\n",
      "        (mlp): SequentialCell<\n",
      "          (0): SiLU<>\n",
      "          (1): Dense<input_channels=96, output_channels=48, has_bias=True>\n",
      "          >\n",
      "        (block1): Block<\n",
      "          (proj): WeightStandardizedConv2d<input_channels=16, output_channels=24, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>\n",
      "          (norm): GroupNorm<num_groups=8, num_channels=24>\n",
      "          (act): SiLU<>\n",
      "          >\n",
      "        (block2): Block<\n",
      "          (proj): WeightStandardizedConv2d<input_channels=24, output_channels=24, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>\n",
      "          (norm): GroupNorm<num_groups=8, num_channels=24>\n",
      "          (act): SiLU<>\n",
      "          >\n",
      "        (res_conv): Conv2d<input_channels=16, output_channels=24, kernel_size=(1, 1), stride=(1, 1), pad_mode=valid, padding=0, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>\n",
      "        >\n",
      "      (1): ResnetBlock<\n",
      "        (mlp): SequentialCell<\n",
      "          (0): SiLU<>\n",
      "          (1): Dense<input_channels=96, output_channels=48, has_bias=True>\n",
      "          >\n",
      "        (block1): Block<\n",
      "          (proj): WeightStandardizedConv2d<input_channels=24, output_channels=24, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>\n",
      "          (norm): GroupNorm<num_groups=8, num_channels=24>\n",
      "          (act): SiLU<>\n",
      "          >\n",
      "        (block2): Block<\n",
      "          (proj): WeightStandardizedConv2d<input_channels=24, output_channels=24, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>\n",
      "          (norm): GroupNorm<num_groups=8, num_channels=24>\n",
      "          (act): SiLU<>\n",
      "          >\n",
      "        (res_conv): Identity<>\n",
      "        >\n",
      "      (2): Residual<\n",
      "        (fn): PreNorm<\n",
      "          (fn): LinearAttention<\n",
      "            (to_qkv): Conv2d<input_channels=24, output_channels=384, kernel_size=(1, 1), stride=(1, 1), pad_mode=valid, padding=0, dilation=(1, 1), group=1, has_bias=False, weight_init=normal, bias_init=zeros, format=NCHW>\n",
      "            (to_out): SequentialCell<\n",
      "              (0): Conv2d<input_channels=128, output_channels=24, kernel_size=(1, 1), stride=(1, 1), pad_mode=valid, padding=0, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>\n",
      "              (1): LayerNorm<>\n",
      "              >\n",
      "            (bmm): BMM<>\n",
      "            >\n",
      "          (norm): GroupNorm<num_groups=1, num_channels=24>\n",
      "          >\n",
      "        >\n",
      "      (3): Conv2d<input_channels=24, output_channels=24, kernel_size=(4, 4), stride=(2, 2), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>\n",
      "      >\n",
      "    (1): CellList<\n",
      "      (0): ResnetBlock<\n",
      "        (mlp): SequentialCell<\n",
      "          (0): SiLU<>\n",
      "          (1): Dense<input_channels=96, output_channels=96, has_bias=True>\n",
      "          >\n",
      "        (block1): Block<\n",
      "          (proj): WeightStandardizedConv2d<input_channels=24, output_channels=48, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>\n",
      "          (norm): GroupNorm<num_groups=8, num_channels=48>\n",
      "          (act): SiLU<>\n",
      "          >\n",
      "        (block2): Block<\n",
      "          (proj): WeightStandardizedConv2d<input_channels=48, output_channels=48, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>\n",
      "          (norm): GroupNorm<num_groups=8, num_channels=48>\n",
      "          (act): SiLU<>\n",
      "          >\n",
      "        (res_conv): Conv2d<input_channels=24, output_channels=48, kernel_size=(1, 1), stride=(1, 1), pad_mode=valid, padding=0, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>\n",
      "        >\n",
      "      (1): ResnetBlock<\n",
      "        (mlp): SequentialCell<\n",
      "          (0): SiLU<>\n",
      "          (1): Dense<input_channels=96, output_channels=96, has_bias=True>\n",
      "          >\n",
      "        (block1): Block<\n",
      "          (proj): WeightStandardizedConv2d<input_channels=48, output_channels=48, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>\n",
      "          (norm): GroupNorm<num_groups=8, num_channels=48>\n",
      "          (act): SiLU<>\n",
      "          >\n",
      "        (block2): Block<\n",
      "          (proj): WeightStandardizedConv2d<input_channels=48, output_channels=48, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>\n",
      "          (norm): GroupNorm<num_groups=8, num_channels=48>\n",
      "          (act): SiLU<>\n",
      "          >\n",
      "        (res_conv): Identity<>\n",
      "        >\n",
      "      (2): Residual<\n",
      "        (fn): PreNorm<\n",
      "          (fn): LinearAttention<\n",
      "            (to_qkv): Conv2d<input_channels=48, output_channels=384, kernel_size=(1, 1), stride=(1, 1), pad_mode=valid, padding=0, dilation=(1, 1), group=1, has_bias=False, weight_init=normal, bias_init=zeros, format=NCHW>\n",
      "            (to_out): SequentialCell<\n",
      "              (0): Conv2d<input_channels=128, output_channels=48, kernel_size=(1, 1), stride=(1, 1), pad_mode=valid, padding=0, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>\n",
      "              (1): LayerNorm<>\n",
      "              >\n",
      "            (bmm): BMM<>\n",
      "            >\n",
      "          (norm): GroupNorm<num_groups=1, num_channels=48>\n",
      "          >\n",
      "        >\n",
      "      (3): Conv2d<input_channels=48, output_channels=48, kernel_size=(4, 4), stride=(2, 2), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>\n",
      "      >\n",
      "    (2): CellList<\n",
      "      (0): ResnetBlock<\n",
      "        (mlp): SequentialCell<\n",
      "          (0): SiLU<>\n",
      "          (1): Dense<input_channels=96, output_channels=192, has_bias=True>\n",
      "          >\n",
      "        (block1): Block<\n",
      "          (proj): WeightStandardizedConv2d<input_channels=48, output_channels=96, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>\n",
      "          (norm): GroupNorm<num_groups=8, num_channels=96>\n",
      "          (act): SiLU<>\n",
      "          >\n",
      "        (block2): Block<\n",
      "          (proj): WeightStandardizedConv2d<input_channels=96, output_channels=96, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>\n",
      "          (norm): GroupNorm<num_groups=8, num_channels=96>\n",
      "          (act): SiLU<>\n",
      "          >\n",
      "        (res_conv): Conv2d<input_channels=48, output_channels=96, kernel_size=(1, 1), stride=(1, 1), pad_mode=valid, padding=0, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>\n",
      "        >\n",
      "      (1): ResnetBlock<\n",
      "        (mlp): SequentialCell<\n",
      "          (0): SiLU<>\n",
      "          (1): Dense<input_channels=96, output_channels=192, has_bias=True>\n",
      "          >\n",
      "        (block1): Block<\n",
      "          (proj): WeightStandardizedConv2d<input_channels=96, output_channels=96, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>\n",
      "          (norm): GroupNorm<num_groups=8, num_channels=96>\n",
      "          (act): SiLU<>\n",
      "          >\n",
      "        (block2): Block<\n",
      "          (proj): WeightStandardizedConv2d<input_channels=96, output_channels=96, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>\n",
      "          (norm): GroupNorm<num_groups=8, num_channels=96>\n",
      "          (act): SiLU<>\n",
      "          >\n",
      "        (res_conv): Identity<>\n",
      "        >\n",
      "      (2): Residual<\n",
      "        (fn): PreNorm<\n",
      "          (fn): LinearAttention<\n",
      "            (to_qkv): Conv2d<input_channels=96, output_channels=384, kernel_size=(1, 1), stride=(1, 1), pad_mode=valid, padding=0, dilation=(1, 1), group=1, has_bias=False, weight_init=normal, bias_init=zeros, format=NCHW>\n",
      "            (to_out): SequentialCell<\n",
      "              (0): Conv2d<input_channels=128, output_channels=96, kernel_size=(1, 1), stride=(1, 1), pad_mode=valid, padding=0, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>\n",
      "              (1): LayerNorm<>\n",
      "              >\n",
      "            (bmm): BMM<>\n",
      "            >\n",
      "          (norm): GroupNorm<num_groups=1, num_channels=96>\n",
      "          >\n",
      "        >\n",
      "      (3): Identity<>\n",
      "      >\n",
      "    >\n",
      "  (ups): CellList<\n",
      "    (0): CellList<\n",
      "      (0): ResnetBlock<\n",
      "        (mlp): SequentialCell<\n",
      "          (0): SiLU<>\n",
      "          (1): Dense<input_channels=96, output_channels=96, has_bias=True>\n",
      "          >\n",
      "        (block1): Block<\n",
      "          (proj): WeightStandardizedConv2d<input_channels=192, output_channels=48, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>\n",
      "          (norm): GroupNorm<num_groups=8, num_channels=48>\n",
      "          (act): SiLU<>\n",
      "          >\n",
      "        (block2): Block<\n",
      "          (proj): WeightStandardizedConv2d<input_channels=48, output_channels=48, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>\n",
      "          (norm): GroupNorm<num_groups=8, num_channels=48>\n",
      "          (act): SiLU<>\n",
      "          >\n",
      "        (res_conv): Conv2d<input_channels=192, output_channels=48, kernel_size=(1, 1), stride=(1, 1), pad_mode=valid, padding=0, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>\n",
      "        >\n",
      "      (1): ResnetBlock<\n",
      "        (mlp): SequentialCell<\n",
      "          (0): SiLU<>\n",
      "          (1): Dense<input_channels=96, output_channels=96, has_bias=True>\n",
      "          >\n",
      "        (block1): Block<\n",
      "          (proj): WeightStandardizedConv2d<input_channels=48, output_channels=48, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>\n",
      "          (norm): GroupNorm<num_groups=8, num_channels=48>\n",
      "          (act): SiLU<>\n",
      "          >\n",
      "        (block2): Block<\n",
      "          (proj): WeightStandardizedConv2d<input_channels=48, output_channels=48, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>\n",
      "          (norm): GroupNorm<num_groups=8, num_channels=48>\n",
      "          (act): SiLU<>\n",
      "          >\n",
      "        (res_conv): Identity<>\n",
      "        >\n",
      "      (2): Residual<\n",
      "        (fn): PreNorm<\n",
      "          (fn): LinearAttention<\n",
      "            (to_qkv): Conv2d<input_channels=48, output_channels=384, kernel_size=(1, 1), stride=(1, 1), pad_mode=valid, padding=0, dilation=(1, 1), group=1, has_bias=False, weight_init=normal, bias_init=zeros, format=NCHW>\n",
      "            (to_out): SequentialCell<\n",
      "              (0): Conv2d<input_channels=128, output_channels=48, kernel_size=(1, 1), stride=(1, 1), pad_mode=valid, padding=0, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>\n",
      "              (1): LayerNorm<>\n",
      "              >\n",
      "            (bmm): BMM<>\n",
      "            >\n",
      "          (norm): GroupNorm<num_groups=1, num_channels=48>\n",
      "          >\n",
      "        >\n",
      "      (3): SequentialCell<\n",
      "        (0): Upsample_cls<>\n",
      "        (1): Conv2d<input_channels=48, output_channels=48, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>\n",
      "        >\n",
      "      >\n",
      "    (1): CellList<\n",
      "      (0): ResnetBlock<\n",
      "        (mlp): SequentialCell<\n",
      "          (0): SiLU<>\n",
      "          (1): Dense<input_channels=96, output_channels=48, has_bias=True>\n",
      "          >\n",
      "        (block1): Block<\n",
      "          (proj): WeightStandardizedConv2d<input_channels=96, output_channels=24, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>\n",
      "          (norm): GroupNorm<num_groups=8, num_channels=24>\n",
      "          (act): SiLU<>\n",
      "          >\n",
      "        (block2): Block<\n",
      "          (proj): WeightStandardizedConv2d<input_channels=24, output_channels=24, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>\n",
      "          (norm): GroupNorm<num_groups=8, num_channels=24>\n",
      "          (act): SiLU<>\n",
      "          >\n",
      "        (res_conv): Conv2d<input_channels=96, output_channels=24, kernel_size=(1, 1), stride=(1, 1), pad_mode=valid, padding=0, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>\n",
      "        >\n",
      "      (1): ResnetBlock<\n",
      "        (mlp): SequentialCell<\n",
      "          (0): SiLU<>\n",
      "          (1): Dense<input_channels=96, output_channels=48, has_bias=True>\n",
      "          >\n",
      "        (block1): Block<\n",
      "          (proj): WeightStandardizedConv2d<input_channels=24, output_channels=24, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>\n",
      "          (norm): GroupNorm<num_groups=8, num_channels=24>\n",
      "          (act): SiLU<>\n",
      "          >\n",
      "        (block2): Block<\n",
      "          (proj): WeightStandardizedConv2d<input_channels=24, output_channels=24, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>\n",
      "          (norm): GroupNorm<num_groups=8, num_channels=24>\n",
      "          (act): SiLU<>\n",
      "          >\n",
      "        (res_conv): Identity<>\n",
      "        >\n",
      "      (2): Residual<\n",
      "        (fn): PreNorm<\n",
      "          (fn): LinearAttention<\n",
      "            (to_qkv): Conv2d<input_channels=24, output_channels=384, kernel_size=(1, 1), stride=(1, 1), pad_mode=valid, padding=0, dilation=(1, 1), group=1, has_bias=False, weight_init=normal, bias_init=zeros, format=NCHW>\n",
      "            (to_out): SequentialCell<\n",
      "              (0): Conv2d<input_channels=128, output_channels=24, kernel_size=(1, 1), stride=(1, 1), pad_mode=valid, padding=0, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>\n",
      "              (1): LayerNorm<>\n",
      "              >\n",
      "            (bmm): BMM<>\n",
      "            >\n",
      "          (norm): GroupNorm<num_groups=1, num_channels=24>\n",
      "          >\n",
      "        >\n",
      "      (3): SequentialCell<\n",
      "        (0): Upsample_cls<>\n",
      "        (1): Conv2d<input_channels=24, output_channels=24, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>\n",
      "        >\n",
      "      >\n",
      "    >\n",
      "  (mid_block1): ResnetBlock<\n",
      "    (mlp): SequentialCell<\n",
      "      (0): SiLU<>\n",
      "      (1): Dense<input_channels=96, output_channels=192, has_bias=True>\n",
      "      >\n",
      "    (block1): Block<\n",
      "      (proj): WeightStandardizedConv2d<input_channels=96, output_channels=96, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>\n",
      "      (norm): GroupNorm<num_groups=8, num_channels=96>\n",
      "      (act): SiLU<>\n",
      "      >\n",
      "    (block2): Block<\n",
      "      (proj): WeightStandardizedConv2d<input_channels=96, output_channels=96, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>\n",
      "      (norm): GroupNorm<num_groups=8, num_channels=96>\n",
      "      (act): SiLU<>\n",
      "      >\n",
      "    (res_conv): Identity<>\n",
      "    >\n",
      "  (mid_attn): Residual<\n",
      "    (fn): PreNorm<\n",
      "      (fn): Attention<\n",
      "        (to_qkv): Conv2d<input_channels=96, output_channels=384, kernel_size=(1, 1), stride=(1, 1), pad_mode=valid, padding=0, dilation=(1, 1), group=1, has_bias=False, weight_init=normal, bias_init=zeros, format=NCHW>\n",
      "        (to_out): Conv2d<input_channels=128, output_channels=96, kernel_size=(1, 1), stride=(1, 1), pad_mode=valid, padding=0, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>\n",
      "        (bmm): BMM<>\n",
      "        >\n",
      "      (norm): GroupNorm<num_groups=1, num_channels=96>\n",
      "      >\n",
      "    >\n",
      "  (mid_block2): ResnetBlock<\n",
      "    (mlp): SequentialCell<\n",
      "      (0): SiLU<>\n",
      "      (1): Dense<input_channels=96, output_channels=192, has_bias=True>\n",
      "      >\n",
      "    (block1): Block<\n",
      "      (proj): WeightStandardizedConv2d<input_channels=96, output_channels=96, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>\n",
      "      (norm): GroupNorm<num_groups=8, num_channels=96>\n",
      "      (act): SiLU<>\n",
      "      >\n",
      "    (block2): Block<\n",
      "      (proj): WeightStandardizedConv2d<input_channels=96, output_channels=96, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>\n",
      "      (norm): GroupNorm<num_groups=8, num_channels=96>\n",
      "      (act): SiLU<>\n",
      "      >\n",
      "    (res_conv): Identity<>\n",
      "    >\n",
      "  (final_conv): SequentialCell<\n",
      "    (0): ResnetBlock<\n",
      "      (block1): Block<\n",
      "        (proj): WeightStandardizedConv2d<input_channels=24, output_channels=24, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>\n",
      "        (norm): GroupNorm<num_groups=8, num_channels=24>\n",
      "        (act): SiLU<>\n",
      "        >\n",
      "      (block2): Block<\n",
      "        (proj): WeightStandardizedConv2d<input_channels=24, output_channels=24, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>\n",
      "        (norm): GroupNorm<num_groups=8, num_channels=24>\n",
      "        (act): SiLU<>\n",
      "        >\n",
      "      (res_conv): Identity<>\n",
      "      >\n",
      "    (1): Conv2d<input_channels=24, output_channels=1, kernel_size=(3, 3), stride=(1, 1), pad_mode=same, padding=0, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>\n",
      "    >\n",
      "  >>\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from inspect import isfunction\n",
    "from functools import partial\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "# from einops import rearrange\n",
    "\n",
    "def rearrange(head, inputs):\n",
    "    b, hc, x, y = inputs.shape\n",
    "    c = hc // head\n",
    "\n",
    "    return inputs.reshape((b, head, c, x*y))\n",
    "\n",
    "import mindspore as ms\n",
    "import mindspore.nn as nn\n",
    "from mindspore import context, ms_function\n",
    "from mindspore.common.initializer import initializer, HeUniform, Uniform, Normal, _calculate_fan_in_and_fan_out\n",
    "\n",
    "\n",
    "context.set_context(device_target=\"GPU\", mode=1)\n",
    "\n",
    "class Conv2d(nn.Conv2d):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, pad_mode='same', padding=0, dilation=1, group=1, has_bias=True):\n",
    "        super().__init__(in_channels, out_channels, kernel_size, stride, pad_mode, padding, dilation, group, has_bias, weight_init='normal', bias_init='zeros')\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.weight.set_data(initializer(HeUniform(math.sqrt(5)), self.weight.shape))\n",
    "        #self.weight = Parameter(initializer(HeUniform(math.sqrt(5)), self.weight.shape), name='weight')\n",
    "        if self.has_bias:\n",
    "            fan_in, _ = _calculate_fan_in_and_fan_out(self.weight.shape)\n",
    "            bound = 1 / math.sqrt(fan_in)\n",
    "            self.bias.set_data(initializer(Uniform(bound), [self.out_channels]))\n",
    "            \n",
    "            \n",
    "def exists(x):\n",
    "    return x is not None\n",
    "\n",
    "def default(val, d):\n",
    "    if exists(val):\n",
    "        return val\n",
    "    return d() if callable(d) else d\n",
    "\n",
    "class Residual(nn.Cell):\n",
    "    def __init__(self, fn):\n",
    "        super().__init__()\n",
    "        self.fn = fn\n",
    "\n",
    "    def construct(self, x, *args, **kwargs):\n",
    "        return self.fn(x, *args, **kwargs) + x\n",
    "    \n",
    "# \"\"\"Upsample\"\"\"\n",
    "\n",
    "from mindspore.ops import constexpr\n",
    "from mindspore.ops.operations.image_ops import ResizeBilinearV2, ResizeLinear1D\n",
    "from mindspore.ops._primitive_cache import _get_cache_prim\n",
    "from mindspore.common.initializer import initializer, HeUniform, Uniform, Normal, _calculate_fan_in_and_fan_out\n",
    "\n",
    "def Upsample(dim, dim_out=None):\n",
    "    @constexpr\n",
    "    def _check_scale_factor(shape, scale_factor):\n",
    "        if isinstance(scale_factor, tuple) and len(scale_factor) != len(shape[2:]):\n",
    "            raise ValueError(f\"the number of 'scale_fator' must match to inputs.shape[2:], \"\n",
    "                             f\"but get scale_factor={scale_factor}, inputs.shape[2:]={shape[2:]}\")\n",
    "\n",
    "    def _interpolate_output_shape(shape, scales, sizes, mode):\n",
    "        \"\"\"calculate output shape\"\"\"\n",
    "        if sizes is not None:\n",
    "            if mode == \"nearest\":\n",
    "                return sizes\n",
    "            return Tensor(sizes)\n",
    "\n",
    "        ret = ()        \n",
    "        for i in range(len(shape[2:])):\n",
    "            if isinstance(scales, float):\n",
    "                out_i = int(scales * shape[i+2])\n",
    "            else:\n",
    "                out_i = int(scales[i] * shape[i+2])\n",
    "            ret = ret + (out_i,)\n",
    "        if mode == \"nearest\":\n",
    "            return ret\n",
    "        return Tensor(ret)\n",
    "\n",
    "    class Upsample_cls(nn.Cell):\n",
    "        def __init__(self, size = None, scale_factor = None,\n",
    "                     mode: str = 'nearest', align_corners = False):\n",
    "            super().__init__()\n",
    "            if mode not in ['nearest', 'linear', 'bilinear']:\n",
    "                raise ValueError(f'do not support mode :{mode}.')\n",
    "            if size and scale_factor:\n",
    "                raise ValueError(f\"can not set 'size' and 'scale_fator' at the same time.\")\n",
    "            self.size = size\n",
    "            if isinstance(scale_factor, tuple):\n",
    "                self.scale_factor = tuple(float(factor) for factor in scale_factor)\n",
    "            else:\n",
    "                self.scale_factor = float(scale_factor) if scale_factor else None\n",
    "            self.mode = mode\n",
    "            self.align_corners = align_corners\n",
    "\n",
    "        def construct(self, inputs):\n",
    "            inputs_shape = inputs.shape\n",
    "            _check_scale_factor(inputs_shape, self.scale_factor)\n",
    "            sizes = _interpolate_output_shape(inputs_shape, self.scale_factor, self.size, self.mode)\n",
    "            if self.mode == 'nearest':\n",
    "                interpolate = _get_cache_prim(ops.ResizeNearestNeighbor)(sizes, self.align_corners)\n",
    "                return interpolate(inputs)\n",
    "            elif self.mode == 'linear':\n",
    "                interpolate = _get_cache_prim(ResizeLinear1D)('align_corners' if self.align_corners else 'half_pixel')\n",
    "                return interpolate(inputs, sizes)\n",
    "            elif self.mode == 'bilinear':\n",
    "                interpolate = _get_cache_prim(ResizeBilinearV2)(self.align_corners, True if self.align_corners==False else False)\n",
    "                return interpolate(inputs, sizes)\n",
    "            return inputs\n",
    "        \n",
    "    return nn.SequentialCell(\n",
    "            Upsample_cls(scale_factor = 2, mode = 'nearest'),\n",
    "            Conv2d(dim, default(dim_out, dim), 3, padding = 1, pad_mode='pad'))\n",
    "\n",
    "\n",
    "\n",
    "def Downsample(dim):\n",
    "    return Conv2d(dim, dim, 4, 2, pad_mode=\"pad\", padding=1)\n",
    "\n",
    "class SinusoidalPositionEmbeddings(nn.Cell):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        half_dim = self.dim // 2\n",
    "        emb = math.log(10000) / (half_dim - 1)\n",
    "        emb = np.exp(np.arange(half_dim) * - emb)\n",
    "        self.emb = Tensor(emb, mindspore.float32)\n",
    "\n",
    "    def construct(self, x):\n",
    "        emb = x[:, None] * self.emb[None, :]\n",
    "        emb = ops.concat((ops.sin(emb), ops.cos(emb)), axis=-1)\n",
    "        return emb\n",
    "    \n",
    "class Identity(nn.Cell):\n",
    "    def construct(self, inputs):\n",
    "        return inputs\n",
    "\n",
    "class WeightStandardizedConv2d(Conv2d):\n",
    "    \"\"\"\n",
    "    https://arxiv.org/abs/1903.10520\n",
    "    weight standardization purportedly works synergistically with group normalization\n",
    "    \"\"\"\n",
    "    def construct(self, x):\n",
    "        eps = 1e-5\n",
    "\n",
    "        weight = self.weight\n",
    "        mean = weight.mean((1, 2, 3), keep_dims=True)\n",
    "        var = weight.var((1, 2, 3), keepdims=True)\n",
    "        normalized_weight = (weight - mean) * rsqrt((var + eps))\n",
    "\n",
    "        output = self.conv2d(x, normalized_weight.astype(x.dtype))\n",
    "        if self.has_bias:\n",
    "            output = self.bias_add(output, self.bias)\n",
    "        return output\n",
    "\n",
    "class Block(nn.Cell):\n",
    "    def __init__(self, dim, dim_out, groups = 8):\n",
    "        super().__init__()\n",
    "        self.proj = WeightStandardizedConv2d(dim, dim_out, 3, padding = 1, pad_mode='pad')\n",
    "        self.norm = nn.GroupNorm(groups, dim_out)\n",
    "        self.act = nn.SiLU()\n",
    "\n",
    "    def construct(self, x, scale_shift = None):\n",
    "        x = self.proj(x)\n",
    "        x = self.norm(x)\n",
    "\n",
    "        if exists(scale_shift):\n",
    "            scale, shift = scale_shift\n",
    "            x = x * (scale + 1) + shift\n",
    "\n",
    "        x = self.act(x)\n",
    "        return x\n",
    "\n",
    "class ResnetBlock(nn.Cell):\n",
    "    def __init__(self, dim, dim_out, *, time_emb_dim = None, groups = 8):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.SequentialCell(\n",
    "            nn.SiLU(),\n",
    "            nn.Dense(time_emb_dim, dim_out * 2)\n",
    "        ) if exists(time_emb_dim) else None\n",
    "\n",
    "        self.block1 = Block(dim, dim_out, groups = groups)\n",
    "        self.block2 = Block(dim_out, dim_out, groups = groups)\n",
    "        self.res_conv = Conv2d(dim, dim_out, 1, pad_mode='valid') if dim != dim_out else Identity()\n",
    "\n",
    "    def construct(self, x, time_emb = None):\n",
    "        scale_shift = None\n",
    "        if exists(self.mlp) and exists(time_emb):\n",
    "            time_emb = self.mlp(time_emb)\n",
    "            time_emb = time_emb.expand_dims(-1).expand_dims(-1) \n",
    "            scale_shift = time_emb.split(axis=1, output_num=2)\n",
    "        h = self.block1(x, scale_shift = scale_shift)\n",
    "        h = self.block2(h)\n",
    "        h = h + self.res_conv(x)\n",
    "        return h\n",
    "    \n",
    "from mindspore import ops, Parameter\n",
    "from mindspore.common.initializer import initializer, Normal\n",
    "\n",
    "\n",
    "class BMM(nn.Cell):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.bmm = ops.BatchMatMul()\n",
    "\n",
    "    def construct(self, x, y):\n",
    "        return self.bmm(x, y)\n",
    "    \n",
    "\n",
    "\n",
    "class Attention(nn.Cell):\n",
    "    def __init__(self, dim, heads = 4, dim_head = 32):\n",
    "        super().__init__()\n",
    "        self.scale = dim_head ** -0.5\n",
    "        self.heads = heads\n",
    "        hidden_dim = dim_head * heads\n",
    "\n",
    "        self.to_qkv = Conv2d(dim, hidden_dim * 3, 1, pad_mode='valid', has_bias = False)\n",
    "        self.to_out = Conv2d(hidden_dim, dim, 1, pad_mode='valid', has_bias = True)\n",
    "        self.map = ops.Map()\n",
    "        self.partial = ops.Partial()\n",
    "        self.bmm = BMM()\n",
    "        self.is_ascend = mindspore.get_context('device_target') == 'Ascend'\n",
    "\n",
    "    def construct(self, x):\n",
    "        b, c, h, w = x.shape\n",
    "        qkv = self.to_qkv(x).split(1, 3)\n",
    "        q, k, v = self.map(self.partial(rearrange, self.heads), qkv)\n",
    "\n",
    "        q = q * self.scale\n",
    "\n",
    "        # 'b h d i, b h d j -> b h i j'\n",
    "        if self.is_ascend:\n",
    "            sim = (q.expand_dims(-1) * k.expand_dims(-2)).sum(2)\n",
    "        else:\n",
    "            sim = self.bmm(q.swapaxes(2, 3), k)\n",
    "        attn = softmax(sim, axis=-1)\n",
    "        # 'b h i j, b h d j -> b h i d'\n",
    "        if self.is_ascend:\n",
    "            out = (attn.expand_dims(3) * v.expand_dims(2)).sum(-1)\n",
    "        else:\n",
    "            out = self.bmm(attn, v.swapaxes(2, 3))\n",
    "        # out = rearrange(out, 'b h (x y) d -> b (h d) x y', x = h, y = w)\n",
    "        out = out.swapaxes(-1, -2).reshape((b, -1, h, w))\n",
    "\n",
    "        return self.to_out(out)\n",
    "\n",
    "class LayerNorm(nn.Cell):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.g = Parameter(initializer('ones', (1, dim, 1, 1)), name='g')\n",
    "\n",
    "    def construct(self, x):\n",
    "        eps = 1e-5\n",
    "        var = x.var(1, keepdims=True)\n",
    "        mean = x.mean(1, keep_dims=True)\n",
    "        return (x - mean) * rsqrt((var + eps)) * self.g\n",
    "\n",
    "class LinearAttention(nn.Cell):\n",
    "    def __init__(self, dim, heads = 4, dim_head = 32):\n",
    "        super().__init__()\n",
    "        self.scale = dim_head ** -0.5\n",
    "        self.heads = heads\n",
    "        hidden_dim = dim_head * heads\n",
    "        self.to_qkv = Conv2d(dim, hidden_dim * 3, 1, pad_mode='valid', has_bias = False)\n",
    "\n",
    "        self.to_out = nn.SequentialCell(\n",
    "            Conv2d(hidden_dim, dim, 1, pad_mode='valid', has_bias = True),\n",
    "            LayerNorm(dim)\n",
    "        )\n",
    "\n",
    "        self.map = ops.Map()\n",
    "        self.partial = ops.Partial()\n",
    "        self.bmm = BMM()\n",
    "        self.is_ascend = mindspore.get_context('device_target') == 'Ascend'\n",
    "\n",
    "    def construct(self, x):\n",
    "        b, c, h, w = x.shape\n",
    "        qkv = self.to_qkv(x).split(1, 3)\n",
    "        q, k, v = self.map(self.partial(rearrange, self.heads), qkv)\n",
    "\n",
    "        q = softmax(q, -2)\n",
    "        k = softmax(k, -1)\n",
    "\n",
    "        q = q * self.scale\n",
    "        v = v / (h * w)\n",
    "\n",
    "        # 'b h d n, b h e n -> b h d e'\n",
    "        if self.is_ascend:\n",
    "            context = (k.expand_dims(3) * v.expand_dims(2)).sum(-1)\n",
    "        else:\n",
    "            context = self.bmm(k, v.swapaxes(2, 3))\n",
    "\n",
    "        # 'b h d e, b h d n -> b h e n'\n",
    "        if self.is_ascend:\n",
    "            out = (context.expand_dims(-1) * q.expand_dims(-2)).sum(2)\n",
    "        else:\n",
    "            out = self.bmm(context.swapaxes(2, 3), q)\n",
    "\n",
    "        out = out.reshape((b, -1, h, w))\n",
    "        return self.to_out(out)\n",
    "\n",
    "class PreNorm(nn.Cell):\n",
    "    def __init__(self, dim, fn):\n",
    "        super().__init__()\n",
    "        self.fn = fn\n",
    "        self.norm = nn.GroupNorm(1, dim)\n",
    "\n",
    "    def construct(self, x):\n",
    "        x = self.norm(x)\n",
    "        return self.fn(x)\n",
    "    \n",
    "class Unet(nn.Cell):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim,\n",
    "        init_dim=None,\n",
    "        out_dim=None,\n",
    "        dim_mults=(1, 2, 4, 8),\n",
    "        channels=3,\n",
    "        with_time_emb=True,\n",
    "        resnet_block_groups=8,\n",
    "        use_convnext=False,\n",
    "        convnext_mult=2,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # determine dimensions\n",
    "        self.channels = channels\n",
    "\n",
    "        init_dim = default(init_dim, dim // 3 * 2)\n",
    "        self.init_conv = Conv2d(channels, init_dim, 7, padding=3, pad_mode=\"pad\",has_bias=True)\n",
    "\n",
    "        dims = [init_dim, *map(lambda m: dim * m, dim_mults)]\n",
    "        in_out = list(zip(dims[:-1], dims[1:]))\n",
    "        \n",
    "        block_klass = partial(ResnetBlock, groups=resnet_block_groups)\n",
    "\n",
    "        # time embeddings\n",
    "        if with_time_emb:\n",
    "            time_dim = dim * 4\n",
    "            self.time_mlp = nn.SequentialCell(\n",
    "                SinusoidalPositionEmbeddings(dim),\n",
    "                nn.Dense(dim, time_dim),\n",
    "                nn.GELU(),\n",
    "                nn.Dense(time_dim, time_dim),\n",
    "            )\n",
    "        else:\n",
    "            time_dim = None\n",
    "            self.time_mlp = None\n",
    "\n",
    "        # layers\n",
    "        self.downs = nn.CellList([])\n",
    "        self.ups = nn.CellList([])\n",
    "        num_resolutions = len(in_out)\n",
    "\n",
    "        for ind, (dim_in, dim_out) in enumerate(in_out):\n",
    "            is_last = ind >= (num_resolutions - 1)\n",
    "\n",
    "            self.downs.append(\n",
    "                nn.CellList(\n",
    "                    [\n",
    "                        block_klass(dim_in, dim_out, time_emb_dim=time_dim),\n",
    "                        block_klass(dim_out, dim_out, time_emb_dim=time_dim),\n",
    "                        Residual(PreNorm(dim_out, LinearAttention(dim_out))),\n",
    "                        Downsample(dim_out) if not is_last else Identity(),\n",
    "                    ]\n",
    "                )\n",
    "            )\n",
    "\n",
    "        mid_dim = dims[-1]\n",
    "        self.mid_block1 = block_klass(mid_dim, mid_dim, time_emb_dim=time_dim)\n",
    "        self.mid_attn = Residual(PreNorm(mid_dim, Attention(mid_dim)))\n",
    "        self.mid_block2 = block_klass(mid_dim, mid_dim, time_emb_dim=time_dim)\n",
    "\n",
    "        for ind, (dim_in, dim_out) in enumerate(reversed(in_out[1:])):\n",
    "            is_last = ind >= (num_resolutions - 1)\n",
    "\n",
    "            self.ups.append(\n",
    "                nn.CellList(\n",
    "                    [\n",
    "                        block_klass(dim_out * 2, dim_in, time_emb_dim=time_dim),\n",
    "                        block_klass(dim_in, dim_in, time_emb_dim=time_dim),\n",
    "                        Residual(PreNorm(dim_in, LinearAttention(dim_in))),\n",
    "                        Upsample(dim_in) if not is_last else Identity(),\n",
    "                    ]\n",
    "                )\n",
    "            )\n",
    "\n",
    "        out_dim = default(out_dim, channels)\n",
    "        self.final_conv = nn.SequentialCell(\n",
    "            block_klass(dim, dim), Conv2d(dim, out_dim, 3)\n",
    "        )\n",
    "\n",
    "    def construct(self, x, time):\n",
    "        x = self.init_conv(x)\n",
    "        r = x.copy()\n",
    "        t = self.time_mlp(time) if exists(self.time_mlp) else None\n",
    "\n",
    "        h = []\n",
    "\n",
    "        # downsample\n",
    "        for block1, block2, attn, downsample in self.downs:\n",
    "            x = block1(x, t)\n",
    "            h.append(x)\n",
    "\n",
    "            x = block2(x, t)\n",
    "            x = attn(x)\n",
    "            h.append(x)\n",
    "\n",
    "            x = downsample(x)\n",
    "\n",
    "        x = self.mid_block1(x, t)\n",
    "        x = self.mid_attn(x)\n",
    "        x = self.mid_block2(x, t)\n",
    "\n",
    "        len_h = len(h) - 1\n",
    "        for block1, block2, attn, upsample in self.ups:\n",
    "            x = ops.concat((x, h[len_h]), 1)\n",
    "            len_h -= 1\n",
    "            x = block1(x, t)\n",
    "\n",
    "            x = ops.concat((x, h[len_h]), 1)\n",
    "            len_h -= 1\n",
    "            x = block2(x, t)\n",
    "            x = attn(x)\n",
    "\n",
    "            x = upsample(x)\n",
    "\n",
    "        x = ops.concat((x, r), 1)\n",
    "\n",
    "        x = self.final_res_block(x, t)\n",
    "        return self.final_conv(x)\n",
    "    \n",
    "    \n",
    "def cosine_beta_schedule(timesteps, s = 0.008):\n",
    "    \"\"\"\n",
    "    cosine schedule\n",
    "    as proposed in https://openreview.net/forum?id=-NEXDKk8gZ\n",
    "    \"\"\"\n",
    "    steps = timesteps + 1\n",
    "    x = np.linspace(0, timesteps, steps).astype(np.float32)\n",
    "    alphas_cumprod = np.cos(((x / timesteps) + s) / (1 + s) * math.pi * 0.5) ** 2\n",
    "    alphas_cumprod = alphas_cumprod / alphas_cumprod[0]\n",
    "    betas = 1 - (alphas_cumprod[1:] / alphas_cumprod[:-1])\n",
    "    return np.clip(betas, 0.0001, 0.999)\n",
    "\n",
    "def linear_beta_schedule(timesteps):\n",
    "    beta_start = 0.0001\n",
    "    beta_end = 0.02\n",
    "    return np.linspace(beta_start, beta_end, timesteps).astype(np.float32)\n",
    "\n",
    "\n",
    "def quadratic_beta_schedule(timesteps):\n",
    "    beta_start = 0.0001\n",
    "    beta_end = 0.02\n",
    "    return np.linspace(beta_start**0.5, beta_end**0.5, timesteps).astype(np.float32) ** 2\n",
    "\n",
    "def sigmoid_beta_schedule(timesteps):\n",
    "    beta_start = 0.0001\n",
    "    beta_end = 0.02\n",
    "    betas = torch.linspace(-6, 6, timesteps)\n",
    "    return np.sigmoid(betas) * (beta_end - beta_start).astype(np.float32) + beta_start\n",
    "\n",
    "import numpy as np\n",
    "from mindspore import Tensor\n",
    "import mindspore\n",
    "\n",
    "timesteps = 200\n",
    "\n",
    "# define beta schedule\n",
    "betas = linear_beta_schedule(timesteps=timesteps)\n",
    "\n",
    "# define alphas \n",
    "alphas = 1. - betas\n",
    "alphas_cumprod = np.cumprod(alphas, axis=0)\n",
    "alphas_cumprod_prev = np.pad(alphas_cumprod[:-1], (1, 0), constant_values = 1)\n",
    "\n",
    "sqrt_recip_alphas = Tensor(np.sqrt(1. / alphas))\n",
    "sqrt_alphas_cumprod = Tensor(np.sqrt(alphas_cumprod))\n",
    "sqrt_one_minus_alphas_cumprod = Tensor(np.sqrt(1. - alphas_cumprod))\n",
    "\n",
    "# calculations for posterior q(x_{t-1} | x_t, x_0)\n",
    "posterior_variance = betas * (1. - alphas_cumprod_prev) / (1. - alphas_cumprod)\n",
    "\n",
    "# def extract(a, t, x_shape):\n",
    "#     return a[t, None, None, None]\n",
    "\n",
    "def extract(a, t, x_shape):\n",
    "#     batch_size = t.shape[0]\n",
    "#     out = a.gather(-1, t)\n",
    "#     return out.reshape(batch_size, *((1,) * (len(x_shape) - 1)))\n",
    "#     b = t.shape[0]\n",
    "#     out = a.gather_elements(-1, t)\n",
    "#     print(type(out))\n",
    "#     return out.reshape(b, *((1,) * (len(x_shape) - 1)))\n",
    "    return a[t, None, None, None]\n",
    "\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "url = 'http://images.cocodataset.org/val2017/000000039769.jpg'\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "image\n",
    "\n",
    "\n",
    "from mindspore.dataset.vision import Resize, Inter, CenterCrop, ToTensor, RandomHorizontalFlip, Rescale\n",
    "from download import download\n",
    "from mindspore.dataset import ImageFolderDataset\n",
    "from multiprocessing import cpu_count\n",
    "from mindspore.dataset.vision import RandomHorizontalFlip\n",
    "\n",
    "\n",
    "image_size = 128\n",
    "transforms = [\n",
    "    Resize(image_size, Inter.BILINEAR),\n",
    "    CenterCrop(image_size),\n",
    "    ToTensor()\n",
    "]\n",
    "\n",
    "# url = 'http://images.cocodataset.org/val2017/000000039769.jpg'\n",
    "# path = download(url, './image_cat/jpg', replace=False)\n",
    "path = './image_cat'\n",
    "dataset = ImageFolderDataset(dataset_dir=path, num_parallel_workers=cpu_count(), extensions=['.jpg', '.jpeg', '.png', '.tiff'],\n",
    "                             num_shards=1, shard_id=0, shuffle=False, decode=True)\n",
    "dataset = dataset.project('image')\n",
    "transforms.insert(1, RandomHorizontalFlip())\n",
    "dataset_1 = dataset.map(transforms, 'image')\n",
    "dataset_2 = dataset_1.batch(1, drop_remainder=True)\n",
    "x_start = next(dataset_2.create_tuple_iterator())[0]\n",
    "print(x_start.shape)\n",
    "\n",
    "\n",
    "# forward diffusion\n",
    "from mindspore.ops._primitive_cache import _get_cache_prim\n",
    "\n",
    "def rsqrt(x):\n",
    "    rsqrt_op = _get_cache_prim(ops.Rsqrt)()\n",
    "    return rsqrt_op(x)\n",
    "\n",
    "def randn_like(x, dtype=None):\n",
    "    if dtype is None:\n",
    "        dtype = x.dtype\n",
    "    normal = _get_cache_prim(ops.StandardNormal)()\n",
    "    return normal(x.shape).astype(dtype)\n",
    "\n",
    "def q_sample(x_start, t, noise=None):\n",
    "    if noise is None:\n",
    "        noise = randn_like(x_start)\n",
    "    return (\n",
    "        extract(sqrt_alphas_cumprod, t, x_start.shape) * x_start +\n",
    "        extract(sqrt_one_minus_alphas_cumprod, t, x_start.shape) * noise\n",
    "    )\n",
    "\n",
    "def softmax(x, axis=-1):\n",
    "    if gpu_target:\n",
    "        softmax_ = _get_cache_prim(ops.Softmax)(axis=axis)\n",
    "        return softmax_(x)\n",
    "    exp_ = _get_cache_prim(ops.Exp)()\n",
    "    reduce_sum_ = _get_cache_prim(ops.ReduceSum)(True)\n",
    "\n",
    "    x_max = x.max(axis=axis, keepdims=True)\n",
    "    x_exp = exp_(x - x_max)\n",
    "    partion = reduce_sum_(x_exp, axis)\n",
    "    return x_exp / partion\n",
    "\n",
    "\n",
    "import mindspore.ops as ops\n",
    "\n",
    "\n",
    "def p_losses(unet_model, x_start, t, noise=None):\n",
    "    if noise is None:\n",
    "        noise = randn_like(x_start)\n",
    "    x_noisy = q_sample(x_start=x_start, t=t, noise=noise)\n",
    "    predicted_noise = unet_model(x_noisy, t)\n",
    "\n",
    "    loss = nn.SmoothL1Loss()(noise, predicted_noise)\n",
    "\n",
    "    return loss\n",
    "\n",
    "from mindspore.dataset import FashionMnistDataset\n",
    "\n",
    "fashion_mnist_dataset_dir = \"./dataset\"\n",
    "# # fashion_mnist_dataset_dir = download(url, fashion_mnist_dataset_dir )\n",
    "dataset = FashionMnistDataset(dataset_dir=fashion_mnist_dataset_dir, num_parallel_workers=cpu_count(), shuffle=True, \n",
    "                            num_shards=1, shard_id=0)\n",
    "transfroms = [\n",
    "        RandomHorizontalFlip(),\n",
    "        ToTensor(),  \n",
    "        lambda t: (t * 2) - 1\n",
    "]\n",
    "\n",
    "dataset = dataset.project('image')\n",
    "dataset = dataset.shuffle(64)\n",
    "dataset = dataset.map(transfroms, 'image')\n",
    "dataset = dataset.batch(128, drop_remainder=True)\n",
    "\n",
    "x = next(dataset.create_dict_iterator())\n",
    "print(x.keys())\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "@ms_function\n",
    "def p_sample(model, x, t, t_index):\n",
    "    betas_t = extract(betas, t, x.shape)\n",
    "    sqrt_one_minus_alphas_cumprod_t = extract(\n",
    "        sqrt_one_minus_alphas_cumprod, t, x.shape\n",
    "    )\n",
    "    sqrt_recip_alphas_t = extract(sqrt_recip_alphas, t, x.shape)\n",
    "    model_mean = sqrt_recip_alphas_t * (\n",
    "        x - betas_t * model(x, t) / sqrt_one_minus_alphas_cumprod_t\n",
    "    )\n",
    "    \n",
    "    def sqrt(x):\n",
    "        return ops.sqrt(x.astype(mindspore.float32))\n",
    "\n",
    "    if t_index == 0:\n",
    "        return model_mean\n",
    "    else:\n",
    "        posterior_variance_t = extract(posterior_variance, t, x.shape)\n",
    "        noise = randn_like(x)\n",
    "        # Algorithm 2 line 4:\n",
    "        return model_mean + sqrt(posterior_variance_t) * noise \n",
    "\n",
    "# Algorithm 2 but save all images:\n",
    "def randn(shape, dtype=None):\n",
    "    if dtype is None:\n",
    "        dtype = mindspore.float32\n",
    "    normal = _get_cache_prim(ops.StandardNormal)()\n",
    "    return normal(shape).astype(dtype)\n",
    "\n",
    "def p_sample_loop(model, shape):\n",
    "    b = shape[0]\n",
    "    \n",
    "    # start from pure noise (for each example in the batch)\n",
    "    img = randn(shape, dtype=None)\n",
    "    imgs = []\n",
    "    \n",
    "    for i in tqdm(reversed(range(0, timesteps)), desc='sampling loop time step', total=timesteps):\n",
    "        img = p_sample(model, img, np.full((b,), i))\n",
    "        imgs.append(img.asnumpy())\n",
    "    return imgs\n",
    "\n",
    "def sample(model, image_size, batch_size=16, channels=3):\n",
    "    return p_sample_loop(model, shape=(batch_size, channels, image_size, image_size))\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "def num_to_groups(num, divisor):\n",
    "    groups = num // divisor\n",
    "    remainder = num % divisor\n",
    "    arr = [divisor] * groups\n",
    "    if remainder > 0:\n",
    "        arr.append(remainder)\n",
    "    return arr\n",
    "\n",
    "results_folder = Path(\"./results\")\n",
    "results_folder.mkdir(exist_ok = True)\n",
    "save_and_sample_every = 1000\n",
    "\n",
    "\n",
    "from mindspore import Tensor, Parameter, context, ms_class\n",
    "import mindspore.common.dtype as mstype\n",
    "\n",
    "@ms_class\n",
    "class LossScaler():\n",
    "    \"\"\"\n",
    "    Basic LossScaler.\n",
    "    \"\"\"\n",
    "    def __init__(self, scale_value):\n",
    "        super().__init__()\n",
    "        self.scale_value = Parameter(Tensor(scale_value, dtype=mstype.float32), name=\"scale_value\")\n",
    "        self.counter = Parameter(Tensor(0, dtype=mstype.int32), name=\"counter\")\n",
    "\n",
    "    def scale(self, inputs):\n",
    "        \"\"\"scale inputs tensor.\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def unscale(self, inputs):\n",
    "        \"\"\"unscale inputs tensor.\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def adjust(self, grads_finite):\n",
    "        \"\"\"adjust scale value.\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "class NoLossScaler(LossScaler):\n",
    "    \"\"\"\n",
    "    No LossScaler\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__(1)\n",
    "\n",
    "    def scale(self, inputs):\n",
    "        return inputs\n",
    "\n",
    "    def unscale(self, inputs):\n",
    "        return inputs\n",
    "\n",
    "    def adjust(self, grads_finite):\n",
    "        return True\n",
    "    \n",
    "loss_scaler = NoLossScaler()\n",
    "\n",
    "\n",
    "###### device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "image_size = 24\n",
    "channels = 1\n",
    "\n",
    "model = Unet(\n",
    "    dim=image_size,\n",
    "    channels=channels,\n",
    "    dim_mults=(1, 2, 4,)\n",
    ")\n",
    "print(model.parameters_and_names)\n",
    "\n",
    "\n",
    "name_list = []\n",
    "for (name, par) in list(model.parameters_and_names()):\n",
    "    name_list.append(name)\n",
    "i = 0\n",
    "for item in list(model.trainable_params()):\n",
    "    item.name = name_list[i]\n",
    "    i+=1\n",
    "    \n",
    "\n",
    "optimizer = nn.Adam(model.trainable_params(), learning_rate=1e-3)\n",
    "\n",
    "# For Loss Scaler\n",
    "ascend_target = (context.get_context(\"device_target\") == \"Ascend\")\n",
    "gpu_target = (context.get_context(\"device_target\") == \"GPU\")\n",
    "reciprocal = ops.Reciprocal()\n",
    "\n",
    "gpu_float_status = ops.FloatStatus()\n",
    "npu_alloc_float_status = ops.NPUAllocFloatStatus()\n",
    "npu_clear_float_status = ops.NPUClearFloatStatus()\n",
    "npu_get_float_status = ops.NPUGetFloatStatus()\n",
    "if ascend_target:\n",
    "    status = npu_alloc_float_status()\n",
    "    _ = npu_clear_float_status(status)\n",
    "else:\n",
    "    status = None\n",
    "\n",
    "hypermap = ops.HyperMap()\n",
    "partial = ops.Partial()\n",
    "\n",
    "\n",
    "def grad_unscale(scale, grad):\n",
    "    \"\"\"grad unscale.\"\"\"\n",
    "    return grad * reciprocal(scale).astype(grad.dtype)\n",
    "\n",
    "def grad_scale(scale, grad):\n",
    "    \"\"\"grad scale.\"\"\"\n",
    "    return grad * scale.astype(grad.dtype)\n",
    "\n",
    "def is_finite(inputs):\n",
    "    \"\"\"whether input tensor is finite.\"\"\"\n",
    "    if gpu_target:\n",
    "        return gpu_float_status(inputs)[0] == 0\n",
    "    status = ops.isfinite(inputs)\n",
    "    return status.all()\n",
    "\n",
    "def all_finite(inputs):\n",
    "    \"\"\"whether all inputs tensor are finite.\"\"\"\n",
    "    if ascend_target:\n",
    "        status = ops.depend(status, inputs)\n",
    "        get_status = npu_get_float_status(status)\n",
    "        status = ops.depend(status, get_status)\n",
    "        status_finite = status.sum() == 0\n",
    "        _ = npu_clear_float_status(status)\n",
    "        return status_finite\n",
    "    outputs = hypermap(partial(is_finite), inputs)\n",
    "    return ops.stack(outputs).all()\n",
    "\n",
    "from mindspore.ops import stop_gradient, GradOperation\n",
    "\n",
    "grad_func = GradOperation(True, False, False)\n",
    "grad_cell = GradOperation(False, True, False)\n",
    "\n",
    "\n",
    "def value_and_grad(fn, pos=None, params=None, has_aux=False):\n",
    "    if params is None:\n",
    "        grad_ = grad_func\n",
    "    else:\n",
    "        grad_ = grad_cell\n",
    "\n",
    "    def fn_aux(*args):\n",
    "        outputs = fn(*args)\n",
    "        no_grad_outputs = (outputs[0],)\n",
    "        for out in outputs[1:]:\n",
    "            no_grad_outputs += (stop_gradient(out),)\n",
    "        return no_grad_outputs\n",
    "\n",
    "    if has_aux:\n",
    "        fn_ = fn_aux\n",
    "    else:\n",
    "        fn_ = fn\n",
    "\n",
    "    def value_and_grad_f(*args):\n",
    "        values = fn_(*args)\n",
    "        if params is None:\n",
    "            grads = grad_(fn_)(*args)\n",
    "        else:\n",
    "            grads = grad_(fn_, params)(*args)\n",
    "        return values, grads\n",
    "    return value_and_grad_f\n",
    "\n",
    "def grad(fn, pos=None, params=None, has_aux=False):\n",
    "    value_and_grad_f = value_and_grad(fn, pos, params, has_aux)\n",
    "    def grad_f(*args):\n",
    "        _, g = value_and_grad_f(*args)\n",
    "        return g\n",
    "    return grad_f\n",
    "\n",
    "\n",
    "\n",
    "import mindspore\n",
    "from mindspore import ms_class, Tensor, Parameter, ops\n",
    "\n",
    "def clip_grad_norm(grads, max_norm: float, norm_type: float = 2.0):\n",
    "    if isinstance(grads, mindspore.Tensor):\n",
    "        grads = [grads]\n",
    "    max_norm = float(max_norm)\n",
    "    norm_type = float(norm_type)\n",
    "    if len(grads) == 0:\n",
    "        return [], mindspore.Tensor(0., mindspore.float32)\n",
    "\n",
    "    if norm_type == inf:\n",
    "        norms = [grad.abs().max() for grad in grads]\n",
    "        total_norm = norms[0] if len(norms) == 1 else ops.max(ops.stack(norms))\n",
    "    else:\n",
    "        norms = ()\n",
    "        for grad in grads:\n",
    "            norms += (norm(grad, norm_type),)\n",
    "        total_norm = norm(ops.stack(norms), norm_type)\n",
    "\n",
    "    clip_coef = ops.div(max_norm, (total_norm + ops.scalar_to_tensor(1e-6, mindspore.float32)))\n",
    "    # Note: multiplying by the clamped coef is redundant when the coef is clamped to 1, but doing so\n",
    "    # avoids a `if clip_coef < 1:` conditional which can require a CPU <=> device synchronization\n",
    "    # when the gradients do not reside in CPU memory.\n",
    "    clip_coef_clamped = clip_coef.clip(None, 1.0)\n",
    "    new_grads = ()\n",
    "    for grad in grads:\n",
    "        new_grads += (ops.mul(grad, clip_coef_clamped),)\n",
    "    return new_grads, total_norm\n",
    "\n",
    "@ms_class\n",
    "class Accumulator():\n",
    "    def __init__(self, optimizer, accumulate_step, total_step=None, clip_norm=1.0):\n",
    "        # super().__init__()\n",
    "        self.optimizer = optimizer\n",
    "        self.clip_norm = clip_norm\n",
    "        self.inner_grads = optimizer.parameters.clone(prefix=\"accumulate_\", init='zeros')\n",
    "        self.zeros = optimizer.parameters.clone(prefix=\"zeros_\", init='zeros')\n",
    "        self.counter = Parameter(Tensor(1, mindspore.int32), 'counter_')\n",
    "        assert accumulate_step > 0\n",
    "        self.accumulate_step = accumulate_step\n",
    "        if total_step is not None:\n",
    "            assert total_step > accumulate_step and total_step > 0\n",
    "        self.total_step = total_step\n",
    "        self.map = ops.Map()\n",
    "        self.partial = ops.Partial()\n",
    "    \n",
    "    def __call__(self, grads):\n",
    "        success = self.map(self.partial(ops.assign_add), self.inner_grads, grads)\n",
    "        if self.counter % self.accumulate_step == 0:\n",
    "            clip_grads, _ = clip_grad_norm(self.inner_grads, self.clip_norm)\n",
    "            self.optimizer(clip_grads)\n",
    "            success = self.map(self.partial(ops.assign), self.inner_grads, self.zeros)\n",
    "\n",
    "        ops.assign_add(self.counter, Tensor(1, mindspore.int32))\n",
    "\n",
    "        return success\n",
    "\n",
    "    \n",
    "from mindspore import Tensor, context\n",
    "from mindspore.ops._primitive_cache import _get_cache_prim\n",
    "\n",
    "\n",
    "def randint(low, high, size, dtype=mindspore.int32):\n",
    "    uniform_int = _get_cache_prim(ops.UniformInt)()\n",
    "    return uniform_int(size, Tensor(low, dtype), Tensor(high, dtype)).astype(dtype)\n",
    "\n",
    "\n",
    "def forward_fn(data, t, noise=None):\n",
    "    loss = p_losses(model, data, t, noise)\n",
    "    return loss\n",
    "\n",
    "grad_fn = value_and_grad(forward_fn, None, optimizer.parameters_dict())\n",
    "\n",
    "\n",
    "def train_step(data, t, noise):\n",
    "    loss, grads = grad_fn(data, t, noise)\n",
    "    grads = ops.identity(grads)\n",
    "    status = all_finite(grads)\n",
    "    if status:\n",
    "        loss = loss_scaler.unscale(loss)\n",
    "        grads = loss_scaler.unscale(grads)\n",
    "        accumulator = Accumulator(optimizer,1)\n",
    "        loss = ops.depend(loss, accumulator(grads))\n",
    "        # grads = ops.clip_by_global_norm(grads, 1.0)\n",
    "        # loss = ops.depend(loss, optimizer(grads))\n",
    "    loss_scaler.adjust(status)\n",
    "    optimizer(grads)\n",
    "    return loss    \n",
    "\n",
    "train_step = ms_function(train_step)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "559c128f",
   "metadata": {
    "id": "92b12ed1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 start batch <class 'mindspore.common.tensor.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ERROR] CORE(1060966,7f1e1e202740,python):2022-12-19-09:15:34.965.471 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_1060966/705420399.py]\n",
      "[ERROR] CORE(1060966,7f1e1e202740,python):2022-12-19-09:15:34.967.763 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_1060966/705420399.py]\n",
      "[ERROR] CORE(1060966,7f1e1e202740,python):2022-12-19-09:15:34.987.125 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_1060966/705420399.py]\n",
      "[ERROR] CORE(1060966,7f1e1e202740,python):2022-12-19-09:15:34.989.649 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_1060966/705420399.py]\n",
      "[ERROR] CORE(1060966,7f1e1e202740,python):2022-12-19-09:15:38.181.119 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_1060966/705420399.py]\n",
      "[ERROR] CORE(1060966,7f1e1e202740,python):2022-12-19-09:15:38.181.269 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_1060966/705420399.py]\n",
      "[ERROR] CORE(1060966,7f1e1e202740,python):2022-12-19-09:15:38.181.292 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_1060966/705420399.py]\n",
      "[ERROR] CORE(1060966,7f1e1e202740,python):2022-12-19-09:15:38.181.402 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_1060966/705420399.py]\n",
      "[ERROR] CORE(1060966,7f1e1e202740,python):2022-12-19-09:15:38.181.445 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_1060966/705420399.py]\n",
      "[ERROR] CORE(1060966,7f1e1e202740,python):2022-12-19-09:15:38.181.510 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_1060966/705420399.py]\n",
      "[ERROR] CORE(1060966,7f1e1e202740,python):2022-12-19-09:15:38.181.553 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_1060966/705420399.py]\n",
      "[ERROR] CORE(1060966,7f1e1e202740,python):2022-12-19-09:15:38.181.593 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_1060966/705420399.py]\n",
      "[ERROR] CORE(1060966,7f1e1e202740,python):2022-12-19-09:15:38.181.654 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_1060966/705420399.py]\n",
      "[ERROR] CORE(1060966,7f1e1e202740,python):2022-12-19-09:15:38.181.675 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_1060966/705420399.py]\n",
      "[ERROR] CORE(1060966,7f1e1e202740,python):2022-12-19-09:15:38.181.720 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_1060966/705420399.py]\n",
      "[ERROR] CORE(1060966,7f1e1e202740,python):2022-12-19-09:15:38.181.736 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_1060966/705420399.py]\n",
      "[ERROR] CORE(1060966,7f1e1e202740,python):2022-12-19-09:15:38.181.785 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_1060966/705420399.py]\n",
      "[ERROR] CORE(1060966,7f1e1e202740,python):2022-12-19-09:15:38.181.802 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_1060966/705420399.py]\n",
      "[ERROR] CORE(1060966,7f1e1e202740,python):2022-12-19-09:15:38.181.854 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_1060966/705420399.py]\n",
      "[ERROR] CORE(1060966,7f1e1e202740,python):2022-12-19-09:15:38.181.876 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_1060966/705420399.py]\n",
      "[ERROR] CORE(1060966,7f1e1e202740,python):2022-12-19-09:15:38.181.918 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_1060966/705420399.py]\n",
      "[ERROR] CORE(1060966,7f1e1e202740,python):2022-12-19-09:15:38.181.938 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_1060966/705420399.py]\n",
      "[ERROR] CORE(1060966,7f1e1e202740,python):2022-12-19-09:15:38.181.974 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_1060966/705420399.py]\n",
      "[ERROR] CORE(1060966,7f1e1e202740,python):2022-12-19-09:15:38.182.012 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_1060966/705420399.py]\n",
      "[ERROR] CORE(1060966,7f1e1e202740,python):2022-12-19-09:15:38.182.092 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_1060966/705420399.py]\n",
      "[ERROR] CORE(1060966,7f1e1e202740,python):2022-12-19-09:15:38.182.113 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_1060966/705420399.py]\n",
      "[ERROR] CORE(1060966,7f1e1e202740,python):2022-12-19-09:15:38.182.140 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_1060966/705420399.py]\n",
      "[ERROR] CORE(1060966,7f1e1e202740,python):2022-12-19-09:15:38.182.194 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_1060966/705420399.py]\n",
      "[ERROR] CORE(1060966,7f1e1e202740,python):2022-12-19-09:15:38.182.214 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_1060966/705420399.py]\n",
      "[ERROR] CORE(1060966,7f1e1e202740,python):2022-12-19-09:15:38.183.158 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_1060966/705420399.py]\n",
      "[ERROR] CORE(1060966,7f1e1e202740,python):2022-12-19-09:15:38.195.302 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_1060966/705420399.py]\n",
      "[ERROR] CORE(1060966,7f1e1e202740,python):2022-12-19-09:15:38.265.157 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_1060966/705420399.py]\n",
      "[ERROR] CORE(1060966,7f1e1e202740,python):2022-12-19-09:15:38.326.279 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_1060966/705420399.py]\n",
      "[ERROR] CORE(1060966,7f1e1e202740,python):2022-12-19-09:15:38.328.139 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_1060966/705420399.py]\n",
      "[ERROR] CORE(1060966,7f1e1e202740,python):2022-12-19-09:15:38.332.865 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_1060966/705420399.py]\n",
      "[ERROR] CORE(1060966,7f1e1e202740,python):2022-12-19-09:15:38.333.484 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_1060966/705420399.py]\n",
      "[ERROR] CORE(1060966,7f1e1e202740,python):2022-12-19-09:15:38.334.076 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_1060966/705420399.py]\n",
      "[ERROR] CORE(1060966,7f1e1e202740,python):2022-12-19-09:15:38.335.105 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_1060966/705420399.py]\n",
      "[ERROR] CORE(1060966,7f1e1e202740,python):2022-12-19-09:15:38.337.593 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_1060966/705420399.py]\n",
      "[ERROR] CORE(1060966,7f1e1e202740,python):2022-12-19-09:15:38.339.112 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_1060966/705420399.py]\n",
      "[ERROR] CORE(1060966,7f1e1e202740,python):2022-12-19-09:15:38.340.047 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_1060966/705420399.py]\n",
      "[ERROR] CORE(1060966,7f1e1e202740,python):2022-12-19-09:15:38.341.401 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_1060966/705420399.py]\n",
      "[ERROR] CORE(1060966,7f1e1e202740,python):2022-12-19-09:15:38.342.783 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_1060966/705420399.py]\n",
      "[ERROR] CORE(1060966,7f1e1e202740,python):2022-12-19-09:15:38.343.795 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_1060966/705420399.py]\n",
      "[ERROR] CORE(1060966,7f1e1e202740,python):2022-12-19-09:15:38.344.719 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_1060966/705420399.py]\n",
      "[ERROR] CORE(1060966,7f1e1e202740,python):2022-12-19-09:15:38.345.323 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_1060966/705420399.py]\n",
      "[ERROR] CORE(1060966,7f1e1e202740,python):2022-12-19-09:15:38.345.768 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_1060966/705420399.py]\n",
      "[ERROR] CORE(1060966,7f1e1e202740,python):2022-12-19-09:15:38.347.542 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_1060966/705420399.py]\n",
      "[ERROR] CORE(1060966,7f1e1e202740,python):2022-12-19-09:15:38.348.429 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_1060966/705420399.py]\n",
      "[ERROR] CORE(1060966,7f1e1e202740,python):2022-12-19-09:15:38.350.940 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_1060966/705420399.py]\n",
      "[ERROR] CORE(1060966,7f1e1e202740,python):2022-12-19-09:15:38.350.970 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_1060966/705420399.py]\n",
      "[ERROR] CORE(1060966,7f1e1e202740,python):2022-12-19-09:15:38.350.986 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_1060966/705420399.py]\n",
      "[ERROR] CORE(1060966,7f1e1e202740,python):2022-12-19-09:15:38.351.003 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_1060966/705420399.py]\n",
      "[ERROR] CORE(1060966,7f1e1e202740,python):2022-12-19-09:15:38.351.018 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_1060966/705420399.py]\n",
      "[ERROR] CORE(1060966,7f1e1e202740,python):2022-12-19-09:15:38.351.034 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_1060966/705420399.py]\n",
      "[ERROR] CORE(1060966,7f1e1e202740,python):2022-12-19-09:15:38.351.052 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_1060966/705420399.py]\n",
      "[ERROR] CORE(1060966,7f1e1e202740,python):2022-12-19-09:15:38.351.068 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_1060966/705420399.py]\n",
      "[ERROR] CORE(1060966,7f1e1e202740,python):2022-12-19-09:15:38.351.083 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_1060966/705420399.py]\n",
      "[ERROR] CORE(1060966,7f1e1e202740,python):2022-12-19-09:15:38.351.098 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_1060966/705420399.py]\n",
      "[ERROR] CORE(1060966,7f1e1e202740,python):2022-12-19-09:15:38.351.111 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_1060966/705420399.py]\n",
      "[ERROR] CORE(1060966,7f1e1e202740,python):2022-12-19-09:15:38.351.123 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_1060966/705420399.py]\n",
      "[ERROR] CORE(1060966,7f1e1e202740,python):2022-12-19-09:15:38.351.134 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_1060966/705420399.py]\n",
      "[ERROR] CORE(1060966,7f1e1e202740,python):2022-12-19-09:15:38.351.146 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_1060966/705420399.py]\n",
      "[ERROR] CORE(1060966,7f1e1e202740,python):2022-12-19-09:15:38.351.160 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_1060966/705420399.py]\n",
      "[ERROR] CORE(1060966,7f1e1e202740,python):2022-12-19-09:15:38.351.174 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_1060966/705420399.py]\n",
      "[ERROR] CORE(1060966,7f1e1e202740,python):2022-12-19-09:15:38.351.189 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_1060966/705420399.py]\n",
      "[ERROR] CORE(1060966,7f1e1e202740,python):2022-12-19-09:15:38.351.204 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_1060966/705420399.py]\n",
      "[ERROR] CORE(1060966,7f1e1e202740,python):2022-12-19-09:15:38.351.273 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_1060966/705420399.py]\n",
      "[ERROR] CORE(1060966,7f1e1e202740,python):2022-12-19-09:15:38.351.288 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_1060966/705420399.py]\n",
      "[ERROR] CORE(1060966,7f1e1e202740,python):2022-12-19-09:15:38.351.307 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_1060966/705420399.py]\n",
      "[ERROR] CORE(1060966,7f1e1e202740,python):2022-12-19-09:15:38.351.321 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_1060966/705420399.py]\n",
      "[ERROR] CORE(1060966,7f1e1e202740,python):2022-12-19-09:15:38.351.340 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_1060966/705420399.py]\n",
      "[ERROR] CORE(1060966,7f1e1e202740,python):2022-12-19-09:15:38.351.354 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_1060966/705420399.py]\n",
      "[ERROR] CORE(1060966,7f1e1e202740,python):2022-12-19-09:15:38.351.371 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_1060966/705420399.py]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "For 'Conv2D', 'C_in' of input 'x' shape divide by parameter 'group' must be equal to 'C_in' of input 'weight' shape: 48, but got 'C_in' of input 'x' shape: 144, and 'group': 1.\n\n----------------------------------------------------\n- The Traceback of Net Construct Code:\n----------------------------------------------------\nThe function call stack (See file '/home/hujingsong/zhangying/diffusion/rank_0/om/analyze_fail.dat' for more details. Get instructions about `analyze_fail.dat` at https://www.mindspore.cn/search?inputValue=analyze_fail.dat):\n# 0 In file /tmp/ipykernel_1060966/705420399.py:902\n# 1 In file /tmp/ipykernel_1060966/705420399.py:810\n# 2 In file /tmp/ipykernel_1060966/705420399.py:813\n# 3 In file /tmp/ipykernel_1060966/705420399.py:895\n# 4 In file /tmp/ipykernel_1060966/705420399.py:581\n# 5 In file /tmp/ipykernel_1060966/705420399.py:895\n# 6 In file /tmp/ipykernel_1060966/705420399.py:409\n# 7 In file /tmp/ipykernel_1060966/705420399.py:895\n# 8 In file /tmp/ipykernel_1060966/705420399.py:409\n# 9 In file /tmp/ipykernel_1060966/705420399.py:895\n# 10 In file /tmp/ipykernel_1060966/705420399.py:409\n# 11 In file /tmp/ipykernel_1060966/705420399.py:895\n# 12 In file /tmp/ipykernel_1060966/705420399.py:409\n# 13 In file /tmp/ipykernel_1060966/705420399.py:895\n# 14 In file /tmp/ipykernel_1060966/705420399.py:424\n# 15 In file /tmp/ipykernel_1060966/705420399.py:431\n# 16 In file /tmp/ipykernel_1060966/705420399.py:424\n# 17 In file /tmp/ipykernel_1060966/705420399.py:198\n# 18 In file /tmp/ipykernel_1060966/705420399.py:173\n# 19 In file /tmp/ipykernel_1060966/705420399.py:170\n# 20 In file /tmp/ipykernel_1060966/705420399.py:158\n# 21 In file /tmp/ipykernel_1060966/705420399.py:157\n\n----------------------------------------------------\n- C++ Call Stack: (For framework developers)\n----------------------------------------------------\nmindspore/core/ops/conv2d.cc:214 Conv2dInferShape\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1060966/2189393890.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimesteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmindspore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"epoch:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"start\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"batch\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/hjs/lib/python3.7/site-packages/mindspore/common/api.py\u001b[0m in \u001b[0;36mstaging_specialize\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    592\u001b[0m                 \u001b[0mprocess_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_MindsporeFunctionExecutor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhash_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_signature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocess_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjit_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    595\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/hjs/lib/python3.7/site-packages/mindspore/common/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*arg, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_convert_python_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/hjs/lib/python3.7/site-packages/mindspore/common/api.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    403\u001b[0m             \u001b[0margs_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m         \u001b[0mphase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"precompile_only\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/hjs/lib/python3.7/site-packages/mindspore/common/api.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, args_list, method_name)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mis_compile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: For 'Conv2D', 'C_in' of input 'x' shape divide by parameter 'group' must be equal to 'C_in' of input 'weight' shape: 48, but got 'C_in' of input 'x' shape: 144, and 'group': 1.\n\n----------------------------------------------------\n- The Traceback of Net Construct Code:\n----------------------------------------------------\nThe function call stack (See file '/home/hujingsong/zhangying/diffusion/rank_0/om/analyze_fail.dat' for more details. Get instructions about `analyze_fail.dat` at https://www.mindspore.cn/search?inputValue=analyze_fail.dat):\n# 0 In file /tmp/ipykernel_1060966/705420399.py:902\n# 1 In file /tmp/ipykernel_1060966/705420399.py:810\n# 2 In file /tmp/ipykernel_1060966/705420399.py:813\n# 3 In file /tmp/ipykernel_1060966/705420399.py:895\n# 4 In file /tmp/ipykernel_1060966/705420399.py:581\n# 5 In file /tmp/ipykernel_1060966/705420399.py:895\n# 6 In file /tmp/ipykernel_1060966/705420399.py:409\n# 7 In file /tmp/ipykernel_1060966/705420399.py:895\n# 8 In file /tmp/ipykernel_1060966/705420399.py:409\n# 9 In file /tmp/ipykernel_1060966/705420399.py:895\n# 10 In file /tmp/ipykernel_1060966/705420399.py:409\n# 11 In file /tmp/ipykernel_1060966/705420399.py:895\n# 12 In file /tmp/ipykernel_1060966/705420399.py:409\n# 13 In file /tmp/ipykernel_1060966/705420399.py:895\n# 14 In file /tmp/ipykernel_1060966/705420399.py:424\n# 15 In file /tmp/ipykernel_1060966/705420399.py:431\n# 16 In file /tmp/ipykernel_1060966/705420399.py:424\n# 17 In file /tmp/ipykernel_1060966/705420399.py:198\n# 18 In file /tmp/ipykernel_1060966/705420399.py:173\n# 19 In file /tmp/ipykernel_1060966/705420399.py:170\n# 20 In file /tmp/ipykernel_1060966/705420399.py:158\n# 21 In file /tmp/ipykernel_1060966/705420399.py:157\n\n----------------------------------------------------\n- C++ Call Stack: (For framework developers)\n----------------------------------------------------\nmindspore/core/ops/conv2d.cc:214 Conv2dInferShape\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    step = 0\n",
    "    for _, batch in enumerate(dataset.create_tuple_iterator()):\n",
    "        batch_size = batch[0].shape[0]\n",
    "\n",
    "        # Algorithm 1 line 3: sample t uniformally for every example in the batch\n",
    "        t = randint(0, timesteps, (batch_size,), dtype=mindspore.int32)\n",
    "        print(\"epoch:\",epoch,\"start\", \"batch\", type(batch[0]))\n",
    "        loss = train_step(batch[0], t, noise=None)\n",
    "\n",
    "        if step % 1 == 0:\n",
    "            print(\"Loss:\", loss.item())\n",
    "\n",
    "\n",
    "\n",
    "#         # save generated images\n",
    "#         if step != 0 and step % save_and_sample_every == 0:\n",
    "#             milestone = step // save_and_sample_every\n",
    "#             batches = num_to_groups(4, batch_size)\n",
    "#             all_images_list = list(map(lambda n: sample(model, batch_size=n, channels=channels), batches))\n",
    "#             all_images = torch.cat(all_images_list, dim=0)\n",
    "#             all_images = (all_images + 1) * 0.5\n",
    "#         step+=1\n",
    "# #         save_image(all_images, str(results_folder / f'sample-{milestone}.png'), nrow = 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a0b599",
   "metadata": {
    "id": "e617a66a",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<div class=\"output stream stdout\">\n",
    "\n",
    "    Output:\n",
    "    ----------------------------------------------------------------------------------------------------\n",
    "    Loss: 0.46477368474006653\n",
    "    Loss: 0.12143351882696152\n",
    "    Loss: 0.08106148988008499\n",
    "    Loss: 0.0801810547709465\n",
    "    Loss: 0.06122320517897606\n",
    "    Loss: 0.06310459971427917\n",
    "    Loss: 0.05681884288787842\n",
    "    Loss: 0.05729678273200989\n",
    "    Loss: 0.05497899278998375\n",
    "    Loss: 0.04439849033951759\n",
    "    Loss: 0.05415581166744232\n",
    "    Loss: 0.06020551547408104\n",
    "    Loss: 0.046830907464027405\n",
    "    Loss: 0.051029372960329056\n",
    "    Loss: 0.0478244312107563\n",
    "    Loss: 0.046767622232437134\n",
    "    Loss: 0.04305662214756012\n",
    "    Loss: 0.05216279625892639\n",
    "    Loss: 0.04748568311333656\n",
    "    Loss: 0.05107741802930832\n",
    "    Loss: 0.04588869959115982\n",
    "    Loss: 0.043014321476221085\n",
    "    Loss: 0.046371955424547195\n",
    "    Loss: 0.04952816292643547\n",
    "    Loss: 0.04472338408231735\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead68a92",
   "metadata": {
    "id": "a8337c82",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Sampling (inference)\n",
    "\n",
    "To sample from the model, we can just use our sample function defined above:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a425d126",
   "metadata": {
    "id": "f3d8a814",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# sample 64 images\n",
    "samples = sample(model, image_size=image_size, batch_size=64, channels=channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1504e0f",
   "metadata": {
    "id": "_s-Al2lJ2c8T",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# show a random one\n",
    "random_index = 5\n",
    "plt.imshow(samples[-1][random_index].reshape(image_size, image_size, channels), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050cbc6a",
   "metadata": {
    "id": "26ad579f",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<img src=\"https://drive.google.com/uc?id=1ytnzS7IW7ortC6ub85q7nud1IvXe2QTE\" width=\"300\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704f0fbd",
   "metadata": {
    "id": "0k4H1fmlKvzR",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Seems like the model is capable of generating a nice T-shirt! Keep in mind that the dataset we trained on is pretty low-resolution (28x28).\n",
    "\n",
    "We can also create a gif of the denoising process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa45cca",
   "metadata": {
    "id": "spE1I9aVNwzZ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.animation as animation\n",
    "\n",
    "random_index = 53\n",
    "\n",
    "fig = plt.figure()\n",
    "ims = []\n",
    "for i in range(timesteps):\n",
    "    im = plt.imshow(samples[i][random_index].reshape(image_size, image_size, channels), cmap=\"gray\", animated=True)\n",
    "    ims.append([im])\n",
    "\n",
    "animate = animation.ArtistAnimation(fig, ims, interval=50, blit=True, repeat_delay=1000)\n",
    "animate.save('diffusion.gif')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad0d79a",
   "metadata": {
    "id": "b02eb802",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<img src=\"https://drive.google.com/uc?id=1eyonQWhfmbQsTq8ndsNjw5QSRQ9em9Au\" width=\"500\" />\n",
    "\n",
    "# Follow-up reads\n",
    "\n",
    "Note that the DDPM paper showed that diffusion models are a promising direction for (un)conditional image generation. This has since then (immensely) been improved, most notably for text-conditional image generation. Below, we list some important (but far from exhaustive) follow-up works:\n",
    "\n",
    "- Improved Denoising Diffusion Probabilistic Models ([Nichol et al., 2021](https://arxiv.org/abs/2102.09672)): finds that learning the variance of the conditional distribution (besides the mean) helps in improving performance\n",
    "- Cascaded Diffusion Models for High Fidelity Image Generation ([Ho et al., 2021](https://arxiv.org/abs/2106.15282)): introduce cascaded diffusion, which comprises a pipeline of multiple diffusion models that generate images of increasing resolution for high-fidelity image synthesis\n",
    "- Diffusion Models Beat GANs on Image Synthesis ([Dhariwal et al., 2021](https://arxiv.org/abs/2105.05233)): show that diffusion models can achieve image sample quality superior to the current state-of-the-art generative models by improving the U-Net architecture, as well as introducing classifier guidance\n",
    "- Classifier-Free Diffusion Guidance ([Ho et al., 2021](https://openreview.net/pdf?id=qw8AKxfYbI)): shows that you don't need a classifier for guiding a diffusion model by jointly training a conditional and an unconditional diffusion model with a single neural network\n",
    "- Hierarchical Text-Conditional Image Generation with CLIP Latents (DALL-E 2) ([Ramesh et al., 2022](https://cdn.openai.com/papers/dall-e-2.pdf)): use a prior to turn a text caption into a CLIP image embedding, after which a diffusion model decodes it into an image\n",
    "- Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding (ImageGen) ([Saharia et al., 2022](https://arxiv.org/abs/2205.11487)): shows that combining a large pre-trained language model (e.g. T5) with cascaded diffusion works well for text-to-image synthesis\n",
    "\n",
    "Note that this list only includes important works until the time of writing, which is June 7th, 2022.\n",
    "\n",
    "For now, it seems that the main (perhaps only) disadvantage of diffusion models is that they require multiple forward passes to generate an image (which is not the case for generative models like GANs). However, there's [research going on](https://arxiv.org/abs/2204.13902) that enables high-fidelity generation in as few as 10 denoising steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbaf2ae4",
   "metadata": {
    "id": "YinXsM62JYjn",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "6fe49a34",
    "2d747688",
    "5153024b",
    "592aa765",
    "9ff47fbb",
    "51d9a24c",
    "9a8031b0",
    "06b3fad0",
    "a30368b2",
    "cc01c63b",
    "f70235f8",
    "b02eb802"
   ],
   "provenance": []
  },
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python [conda env:hjs] *",
   "language": "python",
   "name": "conda-env-hjs-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
